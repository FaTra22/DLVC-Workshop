{"cells":[{"cell_type":"markdown","source":"# 2. Image Data Wrangling\n\nIn order to use images as input for CNNs we need to get them in the right shape","metadata":{"deepnote_cell_type":"markdown","cell_id":"00000-fbe54776-dc08-46b6-ac7c-fa1c4ee7208d","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00000-86946b1c-ef17-4d14-8875-db4a1c1c186a","output_cleared":true,"source_hash":"bf8edc4e","execution_millis":683,"execution_start":1606216222321},"source":"import numpy as np\nimport matplotlib.pyplot as plt\nimport pickle","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Load and display Images","metadata":{"deepnote_cell_type":"markdown","cell_id":"00002-ae7e6de4-edae-4b4a-acea-f06921d6f402","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00003-1ce5e41e-5500-49b3-909d-68f936c62d0c","output_cleared":true,"source_hash":"7403db4f","execution_millis":27,"execution_start":1606216224034},"source":"img = plt.imread(\"images/meme.jpeg\")","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00004-802c5ac5-7ee8-400c-b180-05da2b3ce7ef","output_cleared":true,"source_hash":"972a1fbf","execution_millis":304,"execution_start":1606216225178},"source":"print(\"Shape >>>\", img.shape)\nplt.imshow(img)\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00005-d66de8b7-4ea3-4b3b-9e20-93cf0409a425","output_cleared":true,"source_hash":"500c8ee6","execution_millis":2,"execution_start":1605960324380},"source":"img","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Cifar-10 Dataset\n\nGood Image Classification Dataset:\n\n- 60000 Images\n\n- 10 Classes\n\n- 32x32 RGB Images (very small-> fast training)\n\n[source](https://www.cs.toronto.edu/~kriz/cifar.html)","metadata":{"deepnote_cell_type":"markdown","cell_id":"00006-0f943ee2-a1c9-496f-9f82-29fc79f1ab08","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00001-bb1a7287-5e96-480f-a7d7-64fad475dc30","output_cleared":true,"source_hash":"a9e25641","execution_millis":63,"execution_start":1606216397273},"source":"DATA_PATH = \"./cifar-10-batches-py/data_batch_1\"\nwith open(DATA_PATH, 'rb') as fo:\n    data_dict = pickle.load(fo, encoding='bytes')\n\ndata_dict.keys()","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00002-5b1c4f3b-5c98-4b25-9e05-938a588c28fe","output_cleared":true,"source_hash":"17556b98","execution_millis":1,"execution_start":1606216401245},"source":"print(\"Type >>>\", type(data_dict[b'data']))\nprint(\"Shape >>>\", data_dict[b'data'].shape)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00002-7ea38c82-161b-470f-81e6-9151ee8149f4","output_cleared":true,"source_hash":"ba7a241d","execution_millis":1,"execution_start":1606216402988},"source":"data_dict[b'data'] = data_dict[b'data'].reshape(10000, 3, 32, 32)\ndata_dict[b'data'] = data_dict[b'data'].transpose(0, 2,3,1)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00003-1fc302eb-dc55-42c6-b17f-dfb099266c80","output_cleared":true,"source_hash":"febac23a","execution_millis":2,"execution_start":1606216403529},"source":"image = data_dict[b\"data\"][0]","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00004-e1c88e71-8383-414c-9eb5-6845f22c992a","output_cleared":true,"source_hash":"625657f8","execution_millis":166,"execution_start":1606216403978},"source":"plt.imshow(image)\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Lets use a library to load the dataset\n\nImplemented this \"library\" in a university course","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00006-f41d73b9-bf84-4d20-beef-b3d8f01b14c5","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00005-fd596d69-293e-452b-8fb1-52039d93cbd1","output_cleared":true,"source_hash":"5cec03a7","execution_millis":611,"execution_start":1605960324660},"source":"from dlvc.datasets.cifar import Cifar10\nfrom dlvc.dataset import Subset\n\n\ntrain_data = Cifar10(\"./cifar-10-batches-py/\", Subset.TRAINING)\nprint(train_data.data.shape)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","tags":[],"cell_id":"00006-20b92612-d3a4-443b-8dc4-e40540af29dd","output_cleared":true,"source_hash":"e27ce3b8","execution_millis":117,"execution_start":1605960325278},"source":"image = train_data.__getitem__(0)\n\nprint(\"Label >>> {}\".format(image.label))\n\nprint(\"Data Shape >>> {}\".format(image.data.shape))\n\nplt.imshow(image.data)\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"### Image Augmentation\n\nUse Image Augmentation to increase training sample size!\n\n#### Examples of Augmentation ?\n\n![think](images/think.gif)\n\n\n- Flip Image\n\n- Crop Image\n\n- Rotation\n\n- Add Random Noise","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00008-52895ce7-efd1-4afc-ba90-df42aac8d0da","output_cleared":false,"source_hash":"fd38a59d","execution_start":1605807710033,"execution_millis":0}},{"cell_type":"code","metadata":{"deepnote_cell_type":"markdown","tags":[],"cell_id":"00009-8efbb8de-3407-41bb-9dcb-c80e0fc443dd","output_cleared":true,"source_hash":"b916b1cd","execution_millis":112,"execution_start":1605960325414},"source":"def hflip(sample:np.ndarray) -> np.ndarray:\n    '''\n    Flip arrays with shape HWC horizontally with a probability of 0.5.\n    '''\n    return np.flip(sample, axis=1)\n\nplt.imshow(hflip(image.data))\nplt.show()","execution_count":null,"outputs":[]},{"cell_type":"markdown","source":"## Mini Batches\n\nIn order to train our model we need to generate minibatches of our training data.\n\nThis minibatches are again numpy arrays with a shape of (miniBatchSize, Channels, Height, Width).\n\nSo if we want a Mini Batch Size of 50 we have a numpy array with shape (50, 3, 35, 35)\n\n#### Why did we put the channels now in the second position not in the last like before? Any ideas?","metadata":{"deepnote_cell_type":"markdown","cell_id":"00017-c96ad45a-467d-4865-bd0d-5f423be0ca86","output_cleared":false}},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00018-7d53bcc2-2b31-4cdc-838f-04ed995b9374","output_cleared":true,"source_hash":"391e8efb","execution_millis":7,"execution_start":1605960325528},"source":"# Use our library\nfrom dlvc.batches import BatchGenerator\nimport dlvc.ops as ops","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00019-7c3666fc-44b3-4456-918c-ae3a753ff450","output_cleared":true,"source_hash":"c0973a59","execution_millis":2,"execution_start":1605960325539},"source":"op = ops.chain([\n    ops.type_cast(np.float32),\n    ops.add(-127.5),\n    ops.mul(1 / 127.5),\n    ops.hwc2chw()\n])\n\nops_rev = ops.chain([\n    ops.chw2hwc(),\n    ops.mul(127.5),\n    ops.add(127.5),\n    ops.type_cast(np.int64)\n])\n\ntrain_batches = BatchGenerator(dataset=train_data, num=50, shuffle=False, op=op)\n","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00020-dbe57923-1e35-4f00-80be-807c899d280a","output_cleared":true,"source_hash":"1aa0fe61","execution_millis":4,"execution_start":1605960325545},"source":"\nfor mini_batch in train_batches:\n    data = mini_batch.data\n    labels = mini_batch.label\n    print(data.shape)\n    print(data[0].shape)\n    batch_image_1 = data[0]\n    batch_label_1 = labels[0]\n    break","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00021-73761fa8-53f2-42bd-afa5-06ede9410bb0","output_cleared":true,"source_hash":"44c62509","execution_millis":118,"execution_start":1605960325554},"source":"print(\"Label >>>\", batch_label_1)\n\nimage_original = ops_rev(batch_image_1)\nplt.imshow(image_original)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00022-557c46cf-1928-4960-8fc3-7847368a7f6a","output_cleared":true,"source_hash":"66988004","execution_millis":106,"execution_start":1605960325686},"source":"image_scaled = ops.chw2hwc()(batch_image_1)\nplt.imshow(image_scaled)","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00023-a05bacec-fbfd-4206-aa4b-9442290040f8","output_cleared":true,"source_hash":"b623e53d","execution_start":1605960325794,"execution_millis":1},"source":"","execution_count":null,"outputs":[]},{"cell_type":"code","metadata":{"deepnote_cell_type":"code","cell_id":"00024-ae379b0e-4880-43bd-8b41-167966586183","output_cleared":true,"source_hash":"b623e53d","execution_start":1605960325798,"execution_millis":1},"source":"","execution_count":null,"outputs":[]}],"nbformat":4,"nbformat_minor":2,"metadata":{"orig_nbformat":2,"deepnote_notebook_id":"ad92a88a-9052-4d95-a020-2354381a2901","deepnote_execution_queue":[],"kernelspec":{"name":"python3","display_name":"Python 3.9.0 64-bit","metadata":{"interpreter":{"hash":"ac2eaa0ea0ebeafcc7822e65e46aa9d4f966f30b695406963e145ea4a91cd4fc"}}}}}